/**
 * @file WorkflowOrchestrator.ts
 * @description Orchestrates Python code generation from Catalyst workflows
 * 
 * @architecture Phase 2, Task 2.8 - Integration & Activation
 * @created 2025-12-20
 * @author AI (Cline) + Human Review
 * @confidence 8/10 - Core orchestration logic, needs testing with real workflows
 * 
 * @see src/core/workflow/types.ts - Workflow data structures
 * @see src/core/codegen/python/nodes/llm/ - Node-specific generators
 * @see docs/Catalyst documentation/CATALYST_PHASE_2_TASKS.md - Task 2.8
 * 
 * PROBLEM SOLVED:
 * - Need to convert visual workflow graphs to executable Python/FastAPI code
 * - Multiple node types each have their own generator
 * - Must assemble imports, library functions, workflow logic, and API endpoint
 * - Handle node connections and data flow
 * - Generate clean, readable, production-ready Python code
 * 
 * SOLUTION:
 * - Orchestrator that coordinates all node generators
 * - Topological sort of nodes to respect execution order
 * - Collect all dependencies from used nodes
 * - Assemble into complete Python file structure
 * - FastAPI endpoint wraps workflow execution
 * - Proper error handling and logging
 * 
 * DESIGN DECISIONS:
 * - One Python file per workflow (simple deployment)
 * - FastAPI for HTTP endpoint (matches Catalyst spec)
 * - Async/await throughout (modern Python)
 * - Library functions generated at top, workflow logic at bottom
 * - Environment variables for secrets (12-factor app)
 * - Execution context pattern (ctx object)
 * 
 * GENERATED FILE STRUCTURE:
 * ```python
 * """
 * Workflow: <name>
 * Generated by Catalyst
 * """
 * 
 * # Imports
 * from fastapi import FastAPI
 * from groq import AsyncGroq
 * # ...
 * 
 * # Node library functions
 * async def execute_groq_completion(ctx, config):
 *     # ...generated from groq.py.ts
 * 
 * # FastAPI setup
 * app = FastAPI()
 * 
 * # Workflow endpoint
 * @app.post("/workflow/<name>")
 * async def workflow_handler(input_data: dict):
 *     # Execute nodes in order
 *     result_1 = await execute_groq_completion(ctx, {...})
 *     result_2 = await execute_prompt_template(ctx, {...})
 *     return {"result": result_2}
 * 
 * # Main
 * if __name__ == "__main__":
 *     uvicorn.run(app)
 * ```
 * 
 * @security-critical false - generates code, doesn't execute
 * @performance-critical false - offline code generation
 */

import type {
  WorkflowDefinition,
  NodeDefinition,
  NodeType,
  EdgeDefinition,
} from '../../workflow/types';

// Import all node generators
import {
  generateGroqNode,
  getGroqDependencies,
  generateAnthropicNode,
  getAnthropicDependencies,
  generateOpenAINode,
  getOpenAIDependencies,
  generateEmbeddingNode,
  getEmbeddingDependencies,
  generatePromptTemplateNode,
  getPromptTemplateDependencies,
  generateLLMRouterNode,
  getLLMRouterDependencies,
} from './nodes/llm';

import {
  generateHttpEndpointNode,
  getHttpEndpointDependencies,
} from './nodes/triggers';

import {
  generateStreaming,
  getStreamingDeps,
} from './StreamingGenerator';
import { generateStreamingModule } from './templates/streaming.py';

// ============================================================================
// TYPES
// ============================================================================

/**
 * Result of code generation
 */
export interface GenerationResult {
  /** Generated Python code */
  code: string;
  
  /** Python package dependencies */
  dependencies: string[];
  
  /** Workflow name (for filename) */
  workflowName: string;
  
  /** Number of nodes generated */
  nodeCount: number;
  
  /** Warning messages (non-fatal issues) */
  warnings: string[];
}

/**
 * Node generator function type
 * Takes no parameters, returns Python module code
 */
type NodeGenerator = () => string;

/**
 * Dependency getter function type
 * Returns array of Python package requirements
 */
type DependencyGetter = () => string[];

/**
 * Registry mapping node types to their generators
 */
interface NodeGeneratorRegistry {
  generator: NodeGenerator;
  dependencies: DependencyGetter;
}

// ============================================================================
// NODE GENERATOR REGISTRY
// ============================================================================

/**
 * Map node types to their generator functions
 * 
 * This is the central registry that tells the orchestrator
 * how to generate code for each node type.
 * 
 * As new node types are implemented, add them here.
 */
const NODE_GENERATORS: Record<NodeType, NodeGeneratorRegistry | undefined> = {
  // ===== TRIGGERS (Phase 2.10) =====
  httpEndpoint: {
    generator: generateHttpEndpointNode,
    dependencies: getHttpEndpointDependencies,
  },
  
  // ===== LLM NODES (Phase 2) =====
  groqCompletion: {
    generator: generateGroqNode,
    dependencies: getGroqDependencies,
  },
  
  anthropicCompletion: {
    generator: generateAnthropicNode,
    dependencies: getAnthropicDependencies,
  },
  
  openaiCompletion: {
    generator: generateOpenAINode,
    dependencies: getOpenAIDependencies,
  },
  
  embeddingGenerate: {
    generator: generateEmbeddingNode,
    dependencies: getEmbeddingDependencies,
  },
  
  promptTemplate: {
    generator: generatePromptTemplateNode,
    dependencies: getPromptTemplateDependencies,
  },
  
  llmRouter: {
    generator: generateLLMRouterNode,
    dependencies: getLLMRouterDependencies,
  },
  
  azureOpenaiCompletion: undefined,
  agenticToolCall: undefined,
  
  // ===== STUB ENTRIES (Future phases) =====
  // These will be implemented in future phases
  // For now, return undefined and warn user
  
  // Triggers (Future)
  scheduledTask: undefined,
  webhookReceiver: undefined,
  subworkflowTrigger: undefined,
  websocketEndpoint: undefined,
  queueConsumer: undefined,
  
  // Data Operations (Phase 3)
  qdrantSearch: undefined,
  qdrantUpsert: undefined,
  qdrantScroll: undefined,
  qdrantPayload: undefined,
  postgresQuery: undefined,
  directusQuery: undefined,
  graphqlQuery: undefined,
  redisOperation: undefined,
  
  // HTTP Operations (Phase 3)
  httpRequest: undefined,
  gmailOperation: undefined,
  webhookSend: undefined,
  graphqlMutation: undefined,
  
  // Control Flow (Phase 3)
  condition: undefined,
  switch: undefined,
  loop: undefined,
  parallel: undefined,
  aggregate: undefined,
  retry: undefined,
  delay: undefined,
  earlyReturn: undefined,
  
  // Transform Operations (Phase 3)
  editFields: undefined,
  javascriptFunction: undefined,
  pythonFunction: undefined,
  jsonTransform: undefined,
  mapArray: undefined,
  filterArray: undefined,
  reduceArray: undefined,
  splitArray: undefined,
  
  // Streaming (Phase 3)
  streamStart: undefined,
  streamChunk: undefined,
  streamEnd: undefined,
  streamMerge: undefined,
  streamBuffer: undefined,
  
  // Utilities (Phase 4)
  cryptoGenerate: undefined,
  executionData: undefined,
  globalVariable: undefined,
  errorHandler: undefined,
  log: undefined,
  metrics: undefined,
  rateLimit: undefined,
  validate: undefined,
};

// ============================================================================
// MAIN ORCHESTRATOR
// ============================================================================

/**
 * Generate complete Python code from a Catalyst workflow
 * 
 * This is the main entry point for Python code generation.
 * It orchestrates all the individual node generators and assembles
 * them into a complete, runnable Python file.
 * 
 * PROCESS:
 * 1. Validate workflow has nodes
 * 2. Identify which node types are used
 * 3. Generate library code for each unique node type
 * 4. Collect all dependencies
 * 5. Topologically sort nodes by connections
 * 6. Generate workflow execution logic
 * 7. Assemble complete file
 * 
 * @param workflow - Workflow definition from manifest
 * @returns Generation result with code and dependencies
 * 
 * @throws Error if workflow is invalid or contains unimplemented nodes
 * 
 * @example
 * const workflow = workflowStore.getActiveWorkflow();
 * const result = generatePythonWorkflow(workflow);
 * 
 * // Write to file
 * fs.writeFileSync(
 *   `${projectPath}/.catalyst/generated/${result.workflowName}.py`,
 *   result.code
 * );
 * 
 * // Install dependencies
 * // pip install ${result.dependencies.join(' ')}
 */
export function generatePythonWorkflow(
  workflow: WorkflowDefinition
): GenerationResult {
  // Track warnings for user feedback
  const warnings: string[] = [];
  
  // --------------------------------------------------------
  // 1. VALIDATION
  // --------------------------------------------------------
  
  // Get nodes array from map
  const nodes = Object.values(workflow.nodes);
  
  if (nodes.length === 0) {
    throw new Error('Cannot generate code for empty workflow. Add nodes first.');
  }
  
  // --------------------------------------------------------
  // 2. IDENTIFY UNIQUE NODE TYPES
  // --------------------------------------------------------
  
  // Collect unique node types used in workflow
  // We only generate library code for types that are actually used
  const usedNodeTypes = new Set<NodeType>(nodes.map(node => node.type));
  
  // Check for unimplemented node types
  const unimplementedTypes: NodeType[] = [];
  usedNodeTypes.forEach(type => {
    if (!NODE_GENERATORS[type]) {
      unimplementedTypes.push(type);
    }
  });
  
  if (unimplementedTypes.length > 0) {
    throw new Error(
      `Workflow contains unimplemented node types: ${unimplementedTypes.join(', ')}. ` +
      `These nodes will be available in future phases.`
    );
  }
  
  // --------------------------------------------------------
  // 3. GENERATE LIBRARY CODE
  // --------------------------------------------------------
  
  // Generate library functions for each unique node type
  const libraryModules: string[] = [];
  const allDependencies = new Set<string>();
  
  // Add streaming infrastructure (always needed for LLM streaming)
  if (usedNodeTypes.has('groqCompletion') ||
      usedNodeTypes.has('anthropicCompletion') ||
      usedNodeTypes.has('openaiCompletion')) {
    libraryModules.push(generateStreamingModule());
    getStreamingDeps().forEach((dep: string) => allDependencies.add(dep));
  }
  
  // Generate code for each node type
  usedNodeTypes.forEach(type => {
    const registry = NODE_GENERATORS[type];
    if (registry) {
      // Generate library module
      libraryModules.push(registry.generator());
      
      // Collect dependencies
      registry.dependencies().forEach(dep => allDependencies.add(dep));
    }
  });
  
  // --------------------------------------------------------
  // 4. GENERATE WORKFLOW LOGIC
  // --------------------------------------------------------
  
  // For now, simple sequential execution
  // Future: Respect edges and do topological sort
  const workflowLogic = generateWorkflowExecutionLogic(workflow, nodes);
  
  // --------------------------------------------------------
  // 5. ASSEMBLE COMPLETE FILE
  // --------------------------------------------------------
  
  const code = assembleCompleteFile(
    workflow,
    libraryModules,
    workflowLogic,
    warnings
  );
  
  // --------------------------------------------------------
  // 6. RETURN RESULT
  // --------------------------------------------------------
  
  return {
    code,
    dependencies: Array.from(allDependencies),
    workflowName: sanitizeWorkflowName(workflow.name),
    nodeCount: nodes.length,
    warnings,
  };
}

// ============================================================================
// HELPER FUNCTIONS
// ============================================================================

/**
 * Generate workflow execution logic
 * 
 * Creates the FastAPI endpoint that executes the workflow nodes in order.
 * 
 * For MVP: Simple sequential execution
 * Future: Respect edges, parallel execution, conditional branches
 * 
 * @param workflow - Workflow definition
 * @param nodes - Array of nodes to execute
 * @returns Python code for workflow endpoint
 */
function generateWorkflowExecutionLogic(
  workflow: WorkflowDefinition,
  nodes: NodeDefinition[]
): string {
  // Generate node execution calls
  const nodeExecutions = nodes.map((node, index) => {
    const varName = `result_${index + 1}`;
    const functionName = getExecutionFunctionName(node.type);
    const config = JSON.stringify(node.config, null, 4);
    
    return `    # Node: ${node.name} (${node.type})
    ${varName} = await ${functionName}(ctx, ${config})
    logger.info(f"Node '${node.name}' completed")`;
  }).join('\n\n');
  
  // Last result is the workflow output
  const lastResultVar = `result_${nodes.length}`;
  
  return `
@app.post("/workflow/${sanitizeWorkflowName(workflow.name)}")
async def workflow_${sanitizeWorkflowName(workflow.name)}(input_data: dict):
    """
    ${workflow.description || 'Generated workflow endpoint'}
    
    Workflow: ${workflow.name}
    Nodes: ${nodes.length}
    """
    logger.info("Starting workflow: ${workflow.name}")
    
    # Initialize execution context
    # In production, load secrets from environment variables
    ctx = ExecutionContext(
        secrets={
            "GROQ_API_KEY": os.getenv("GROQ_API_KEY"),
            "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY"),
            "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
        },
        input_data=input_data,
    )
    
${nodeExecutions}
    
    logger.info("Workflow completed successfully")
    
    return {
        "status": "success",
        "workflow": "${workflow.name}",
        "result": ${lastResultVar},
    }
`;
}

/**
 * Assemble complete Python file
 * 
 * Combines header, imports, library modules, and workflow logic
 * into a complete, runnable Python file.
 * 
 * @param workflow - Workflow definition
 * @param libraryModules - Generated library code modules
 * @param workflowLogic - Workflow execution endpoint
 * @param warnings - Array to collect warnings
 * @returns Complete Python file as string
 */
function assembleCompleteFile(
  workflow: WorkflowDefinition,
  libraryModules: string[],
  workflowLogic: string,
  warnings: string[]
): string {
  // File header
  const header = `"""
Catalyst Workflow: ${workflow.name}

${workflow.description || 'No description provided'}

@catalyst:generated
DO NOT EDIT - Generated by Catalyst
Changes will be overwritten on next generation

Generated: ${new Date().toISOString()}
Nodes: ${Object.keys(workflow.nodes).length}
Trigger: ${workflow.trigger?.type || 'httpEndpoint'}
"""

import os
import logging
from typing import Any, Dict, Optional
from fastapi import FastAPI, HTTPException
from dataclasses import dataclass

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ============================================================================
# EXECUTION CONTEXT
# ============================================================================

@dataclass
class ExecutionContext:
    """
    Execution context passed to all node functions.
    
    Contains:
    - secrets: API keys and credentials
    - input_data: Input data from workflow trigger
    - state: Workflow state (for future use)
    """
    secrets: Dict[str, str]
    input_data: Dict[str, Any]
    state: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.state is None:
            self.state = {}


# ============================================================================
# FASTAPI APPLICATION
# ============================================================================

app = FastAPI(
    title="${workflow.name}",
    description="${workflow.description || 'Catalyst Generated Workflow'}",
    version="1.0.0",
)


# Health check endpoint
@app.get("/health")
async def health_check():
    """Health check endpoint for monitoring."""
    return {
        "status": "healthy",
        "workflow": "${workflow.name}",
    }
`;

  // Library modules section
  const librarySection = `
# ============================================================================
# NODE LIBRARY FUNCTIONS
# ============================================================================
# Generated library functions for workflow nodes
# Each node type has execute_* and stream_* functions

${libraryModules.join('\n\n')}
`;

  // Workflow logic section
  const workflowSection = `
# ============================================================================
# WORKFLOW ENDPOINTS
# ============================================================================

${workflowLogic}
`;

  // Main section
  const mainSection = `
# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    # Check for required environment variables
    required_env_vars = ["GROQ_API_KEY"]  # Adjust based on nodes used
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.error(f"Missing required environment variables: {', '.join(missing_vars)}")
        logger.error("Please set these variables before running the workflow")
        exit(1)
    
    logger.info("Starting Catalyst workflow server...")
    logger.info(f"Workflow: ${workflow.name}")
    logger.info(f"Nodes: ${Object.keys(workflow.nodes).length}")
    
    # Start server
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
    )
`;

  // Combine all sections
  return header + librarySection + workflowSection + mainSection;
}

/**
 * Get execution function name for a node type
 * 
 * Maps node types to their execute_* function names
 * 
 * @param nodeType - Node type
 * @returns Python function name
 */
function getExecutionFunctionName(nodeType: NodeType): string {
  // Map node types to function names
  const functionNames: Record<NodeType, string> = {
    groqCompletion: 'execute_groq_completion',
    anthropicCompletion: 'execute_anthropic_completion',
    openaiCompletion: 'execute_openai_completion',
    embeddingGenerate: 'execute_embedding_generation',
    promptTemplate: 'execute_prompt_template',
    llmRouter: 'execute_llm_router',
    azureOpenaiCompletion: 'execute_azure_openai_completion',
    agenticToolCall: 'execute_agentic_tool_call',
    
    // Triggers
    httpEndpoint: 'execute_http_endpoint',
    scheduledTask: 'execute_scheduled_task',
    webhookReceiver: 'execute_webhook_receiver',
    subworkflowTrigger: 'execute_subworkflow_trigger',
    websocketEndpoint: 'execute_websocket_endpoint',
    queueConsumer: 'execute_queue_consumer',
    // Data
    qdrantSearch: 'execute_qdrant_search',
    qdrantUpsert: 'execute_qdrant_upsert',
    qdrantScroll: 'execute_qdrant_scroll',
    qdrantPayload: 'execute_qdrant_payload',
    postgresQuery: 'execute_postgres_query',
    directusQuery: 'execute_directus_query',
    graphqlQuery: 'execute_graphql_query',
    redisOperation: 'execute_redis_operation',
    // HTTP
    httpRequest: 'execute_http_request',
    gmailOperation: 'execute_gmail_operation',
    webhookSend: 'execute_webhook_send',
    graphqlMutation: 'execute_graphql_mutation',
    // Control Flow
    condition: 'execute_condition',
    switch: 'execute_switch',
    loop: 'execute_loop',
    parallel: 'execute_parallel',
    aggregate: 'execute_aggregate',
    retry: 'execute_retry',
    delay: 'execute_delay',
    earlyReturn: 'execute_early_return',
    // Transform
    editFields: 'execute_edit_fields',
    javascriptFunction: 'execute_javascript_function',
    pythonFunction: 'execute_python_function',
    jsonTransform: 'execute_json_transform',
    mapArray: 'execute_map_array',
    filterArray: 'execute_filter_array',
    reduceArray: 'execute_reduce_array',
    splitArray: 'execute_split_array',
    // Streaming
    streamStart: 'execute_stream_start',
    streamChunk: 'execute_stream_chunk',
    streamEnd: 'execute_stream_end',
    streamMerge: 'execute_stream_merge',
    streamBuffer: 'execute_stream_buffer',
    // Utilities
    cryptoGenerate: 'execute_crypto_generate',
    executionData: 'execute_execution_data',
    globalVariable: 'execute_global_variable',
    errorHandler: 'execute_error_handler',
    log: 'execute_log',
    metrics: 'execute_metrics',
    rateLimit: 'execute_rate_limit',
    validate: 'execute_validate',
  };
  
  return functionNames[nodeType] || 'execute_unknown_node';
}

/**
 * Sanitize workflow name for use in Python identifiers
 * 
 * Converts workflow name to valid Python identifier:
 * - Lowercase
 * - Replace spaces/special chars with underscores
 * - Remove consecutive underscores
 * 
 * @param name - Workflow name
 * @returns Sanitized name
 * 
 * @example
 * sanitizeWorkflowName("My Workflow!") // "my_workflow"
 * sanitizeWorkflowName("User-API-v2") // "user_api_v2"
 */
function sanitizeWorkflowName(name: string): string {
  return name
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, '_')  // Replace non-alphanumeric with underscore
    .replace(/^_+|_+$/g, '')       // Remove leading/trailing underscores
    .replace(/_+/g, '_')           // Remove consecutive underscores
    || 'workflow';                 // Fallback if name is empty
}
